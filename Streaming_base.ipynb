{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Streaming prediction-error filters\n",
    "\n",
    "Prediction-error filters (PEFs) are essential in seismic deconvolution and other geophysical estimation problems. We show that non-stationary multidimensional PEFs can be computed in a \"streaming\" manner, where the filter gets updated incrementally by accepting one new data point at a time. The computational cost of estimating a streaming PEF reduces to the cost of a single convolution. In other words, the cost of PEF design while filtering equals the cost of applying the filter. Moreover, the non-linear operation of finding and applying a streaming PEF is invertible at a similar cost, which enables a fast approach to missing data interpolation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Prediction-error filters (PEFs) play an essential role in geophysical data analysis. They can be used directly in different forms of seismic deconvolution (Webster, 1978; Robinson & Osman, 1996). More importantly, PEFs are a practical approximation for covariance operators used in geophysical estimation problems (Claerbout, 2014). As such, they provide a way to absorb and characterize statistical patterns in a given dataset (Claerbout & Brown, 1999).\n",
    "\n",
    "Because most natural patterns are non-stationary, extending the classic stationary formulation to non-stationarity is vital. This extension can be done either by \"patching\" or breaking data into overlapping windows or by a smoothly non-stationary estimation with regularization (Crawley et al., 1999; Curry, 2003). Shaping regularization provides a particularly effective method for constraining the filter variability (Fomel, 2009; Liu & Fomel, 2011; Liu et al., 2012). Both approaches have an additional computational expense, particularly in storing variable filter coefficients (Ruan et al., 2015).\n",
    "\n",
    "This paper presents an efficient approach to computing and applying non-stationary PEFs with no excessive storage requirements. Using an adaptive-filtering approach (Widrow \\& Stearns, 1985; Haykin, 2002), We show that a non-stationary PEF can be updated on the fly by accepting one data point at a time. The cost of computing and applying such a PEF reduces to the cost of a single convolution. In other words, the cost of PEF design while filtering equals the cost of applying the filter. Moreover, the non-linear operation of finding and applying a PEF has an exact inverse, which finds an immediate application in missing data interpolation problems. We extend the\n",
    "filter from 1-D to multiple dimensions using the helix transform (Claerbout, 1998) and show its application to simple benchmark problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Theory       \n",
    "\n",
    "The basic equation defining a prediction-error filter is auto-regression. For a given data stream $\\mathbf{d}$ and a one-dimensional PEF $\\mathbf{a}$, the auto-regression equation takes the form\n",
    "\n",
    "$$\\left[\\begin{array}{ccccc} d_{n+1} & d_n & d_{n-1} & \\cdots &\n",
    "                                                   d_{n+1-k} \\end{array}\\right]\\,\n",
    "\\left[\\begin{array}{l} 1 \\\\ a_1 \\\\ a_2 \\\\ \\cdots \\\\ a_k \\end{array}\\right]\n",
    "\\approx 0\\;,$$\n",
    "\n",
    "where it is assumed that $n \\ge k$. Equation 1 represents the convolution of the data with the prediction-error filter.\n",
    "\n",
    "Suppose the filter gets updated with each new data point\n",
    "$d_{n+1}$. The additional constraint we can impose to control\n",
    "the variability of the filter is that the new filter $a$ stays close\n",
    "to the previous filter $\\bar{a}$.\n",
    "\n",
    "The two conditions can be combined into one overdetermined linear system\n",
    "\n",
    "$$\\left[\\begin{array}{cccc} d_n & d_{n-1} & \\cdots & d_{n+1-k} \\\\\n",
    "      \\lambda & 0 & & 0 \\\\\n",
    "      0 & \\lambda & & 0 \\\\\n",
    "    \\cdots & \\cdots & & \\cdots \\\\\n",
    "      0 & 0 & \\cdots & \\lambda\n",
    "    \\end{array}\\right]\\,\n",
    "  \\left[\\begin{array}{l} a_1 \\\\ a_2 \\\\ \\cdots \\\\ a_k \\end{array}\\right] \\approx\n",
    "  \\left[\\begin{array}{l} - d_{n+1} \\\\\n",
    "      \\lambda\\,\\bar{a}_1 \\\\\n",
    "      \\lambda\\,\\bar{a}_2 \\\\\n",
    "     \\cdots \\\\\n",
    "      \\lambda\\,\\bar{a}_k\n",
    "    \\end{array}\\right]\\;,$$\n",
    "\n",
    "where $\\lambda$ is the parameter that controls how much we allow \n",
    "$a$ to deviate from $\\bar{a}$. In a shortened block-matrix notation, we can rewrite the linear system of equations as\n",
    "\n",
    "$$\\left[\\begin{array}{c} \\mathbf{d}^T \\\\ \\lambda\\,\\mathbf{I} \\end{array}\\right]\\,\\mathbf{a} \\approx\n",
    "  \\left[\\begin{array}{l} - d_{n+1} \\\\\n",
    "      \\lambda\\,\\bar{\\mathbf{a}} \n",
    "    \\end{array}\\right]\\;,$$\n",
    "    \n",
    "where\n",
    "\n",
    "$$\\mathbf{d} = \\left[\\begin{array}{l} d_n \\\\ d_{n-1} \\\\ \\cdots \\\\ d_{n+1-k} \\end{array}\\right]\\;, \\quad\n",
    "\\mathbf{a} = \\left[\\begin{array}{l} a_1 \\\\ a_2 \\\\ \\cdots \\\\ a_k \\end{array}\\right]\\;,$$\n",
    "\n",
    "and $\\mathbf{I}$ is the identity matrix. \n",
    "\n",
    "The least-squares solution of the overdetermined system is\n",
    "\n",
    "$$\\mathbf{a} = \\left(\\mathbf{d}\\,\\mathbf{d}^T + \\lambda^2\\,\\mathbf{I}\\right)^{-1}\\,\n",
    "  \\left(-d_{n+1}\\,\\mathbf{d} + \\lambda^2\\,\\bar{\\mathbf{a}}\\right)\\;.$$\n",
    "\n",
    "Next, we can use the Sherman-Morrison formula from linear algebra\n",
    "(Hager, 1989) to transform the inverse matrix as follows:\n",
    "\n",
    "$$\\left(\\mathbf{d}\\,\\mathbf{d}^T + \\lambda^2\\,\\mathbf{I}\\right)^{-1} =\n",
    "  \\frac{1}{\\lambda^2}\\,\\left(\\mathbf{I} - \\frac{\\mathbf{d}\\,\\mathbf{d}^T}{\\lambda^2+\\mathbf{d}^T\\,\\mathbf{d}}\\right)\\;.$$\n",
    "\n",
    "Substituting the Sherman-Morrison equation and doing\n",
    "algebraic simplifications lead to the final result:\n",
    "\n",
    "$$\\begin{array}{rcl}\\mathbf{a} & = & \\displaystyle \\frac{1}{\\lambda^2}\\,\\left(\\mathbf{I} -\n",
    "                   \\frac{\\mathbf{d}\\,\\mathbf{d}^T}{\\lambda^2+\\mathbf{d}^T\\,\\mathbf{d}}\\right)\\,\\left(-d_{n+1}\\,\\mathbf{d}\n",
    "                   + \\lambda^2\\,\\bar{\\mathbf{a}}\\right) \\\\\n",
    "& = &\n",
    "\\displaystyle \\bar{\\mathbf{a}} -\n",
    "  \\left(\\frac{d_{n+1}+\\mathbf{d}^T\\,\\bar{\\mathbf{a}}}{\\lambda^2+\\mathbf{d}^T\\,\\mathbf{d}}\\right)\\,\\mathbf{d}\\;.\\end{array}$$\n",
    "  \n",
    "The Sherman-Morrison technique is a well-known approach in adaptive filtering by recursive least-squares (Haykin, 2002).\n",
    "  \n",
    "This equation shows that the filter is updated by subtracting\n",
    "a scaled version of the data. The scale is proportional to the\n",
    "convolution residual computed using the previous version of the\n",
    "filter. Updating the filter requires only elementary algebraic operations (vector dot products) and no iterations. Moreover, computing the dot product\n",
    "$\\mathbf{d}^T\\,\\mathbf{d}$ in a \"streaming\" fashion requires at most\n",
    "two multiplications:\n",
    "\n",
    "$$\\mathbf{d}^T\\,\\mathbf{d} = \\bar{\\mathbf{d}}^T\\,\\bar{\\mathbf{d}} +\n",
    "d_n^2 - d_{n-k}^2\\;,$$\n",
    "\n",
    "where $k$ is number of points in $\\mathbf{a}$ and $\\mathbf{d}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Inversion\n",
    "\n",
    "The streaming residual $r_{n+1}$ from the left-hand side of\n",
    "equation 1 can be expressed as\n",
    "\n",
    "$$r_{n+1} = d_{n+1} + \\mathbf{d}^T\\,\\mathbf{a}$$\n",
    "\n",
    "or, substituting equation for $\\mathbf{a}$,\n",
    "\n",
    "$$\\begin{array}{rcl}r_{n+1} & = & \\displaystyle d_{n+1} + \\mathbf{d}^T\\,\\left[\\bar{\\mathbf{a}} -\n",
    "              \\left(\\frac{d_{n+1}+\\mathbf{d}^T\\,\\bar{\\mathbf{a}}}{\\lambda^2+\\mathbf{d}^T\\,\\mathbf{d}}\\right)\\,\\mathbf{d}\\right]\n",
    "  \\\\\n",
    "\\nonumber\n",
    "& = & \\displaystyle \\left(d_{n+1} +\n",
    "      \\mathbf{d}^T\\,\\bar{\\mathbf{a}}\\right)\\,\\left(1-\\frac{\\mathbf{d}^T\\,\\mathbf{d}}{\\lambda^2+\\mathbf{d}^T\\,\\mathbf{d}}\\right)\n",
    "  \\\\\n",
    "& = & \\displaystyle \\frac{\\lambda^2\\,\\left(d_{n+1} +\n",
    "  \\mathbf{d}^T\\,\\bar{\\mathbf{a}}\\right)}{\\lambda^2+\\mathbf{d}^T\\,\\mathbf{d}}\\;.\\end{array}$$\n",
    "\n",
    "\n",
    "The equation for $r_{n+1}$ can be directly inverted to reconstruct~$d_{n+1}$ as follows:\n",
    "\n",
    "$$d_{n+1} = r_{n+1}\\,\\left(1+\\frac{\\mathbf{d}^T\\,\\mathbf{d}}{\\lambda^2}\\right) - \\mathbf{d}^T\\,\\bar{\\mathbf{a}}\\;.$$\n",
    "\n",
    "We see that streaming time-variable deconvolution is invertible: both the input data and the time-varying filter can be reconstructed from the streaming residual. Note that because of the division by $\\lambda^2$, the inverse operation may become numerically unstable for small $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1=400\n",
    "\n",
    "# exponentially decaying sinusiods with different frequencies\n",
    "inp = zeros(Float32,n1)\n",
    "for j in n1รท15:n1รท5:n1\n",
    "    wave = zeros(Float32,n1)\n",
    "    for x in j:399\n",
    "        y = (x-j)/400\n",
    "        wave[x] = exp(-y*15)*sin(y*0.95*j)\n",
    "    end\n",
    "    inp += wave\n",
    "end\n",
    "\n",
    "res = similar(inp);\n",
    "bak = similar(inp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg; Pkg.add(\"Plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "\n",
    "function stems(data, label, color) \n",
    "    \"plot data using stems\"\n",
    "    plt=plot(zeros(Float32, n1), label=:none, color=:black)\n",
    "    plot!(plt, data, line=:stem,\n",
    "          label=label, color=color, legend=:outerleft, \n",
    "          xlim=[0.5, n1+0.5], border=:none)   \n",
    "    return plt\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_input = stems(inp,\"input\",:blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "function stream!(inv::Bool, d::Vector{T}, r::Vector{T}, na::Int, ฮป::Real) where T <: Real\n",
    "    a = zeros(T, na) # streaming PEF\n",
    "    dd = da = zero(T) # d (dot) d, d (dot) a\n",
    "    for ia in 1:na\n",
    "        if (inv) \n",
    "            d[ia] = r[ia]\n",
    "        else \n",
    "            r[ia] = d[ia]\n",
    "        end\n",
    "        dd += d[ia]*d[ia]\n",
    "    end\n",
    "    for i1 in na+1:n1\n",
    "        if (inv) # from r to d\n",
    "            rn = r[i1] / ฮป \n",
    "            dn = rn * (ฮป + dd) - da\n",
    "            d[i1] = dn\n",
    "        else     # from d to r\n",
    "            dn = d[i1]\n",
    "            rn = (dn + da) / (ฮป + dd)\n",
    "            r[i1] = ฮป * rn\n",
    "        end\n",
    "        # update PEF\n",
    "        for ia in 1:na; a[ia] -= rn * d[i1-ia]; end\n",
    "        # update dd and da\n",
    "        dd += dn*dn - d[i1-na] * d[i1-na]   \n",
    "        da = dn * a[1]\n",
    "        for ia in 2:na; da += a[ia] * d[i1-ia+1]; end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream!(false, inp, res, 2, 0.1)\n",
    "plot_decon = stems(res, \"decon\", :green);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream!(true, bak, res, 2, 0.1)\n",
    "plot_inverse = stems(bak,\"inverse\",:purple);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(plot_input, plot_decon, plot_inverse, layout=(3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(\"stream.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Multiple dimensions\n",
    "\n",
    "In order to extend the filter from 1-D to multiple dimensions, we follow the\n",
    "helix transform of Claerbout (1998). The change is minimal:\n",
    "the multidimensional data is arranged in a 1D stream on a helix, and\n",
    "the definition of the data vector $\\mathbf{d}$ changes to\n",
    "\n",
    "$$\\mathbf{d} = \\left[\\begin{array}{l} d_{n+1-l_1} \\\\ d_{n+1-l_2} \\\\ \\cdots \\\\ d_{n+1-l_k} \\end{array}\\right]$$\n",
    "\n",
    "where $l_1, l_2, \\ldots, l_k$ represent lags of the helical filter. The computational cost and other benefits of streaming PEFs remain the same.\n",
    "\n",
    "One caveat is that, in multiple dimensions, we may want the\n",
    "nonstationary filter to change smoothly along the helix and other dimensions. As shown below, this goal can be accomplished with only a minor change to the algorithm. Suppose that $\\bar{\\mathbf{a}}_1$ is the previous filter in the first (helical) dimension, and $\\bar{\\mathbf{a}}_2$ is the previous filter in the second dimension. We can keep the newly estimated streaming PEF close to both\n",
    "filters by changing the matrix equation to\n",
    "\n",
    "$$\\left[\\begin{array}{c} \\mathbf{d}^T \\\\ \\lambda_1\\,\\mathbf{I} \\\\  \\lambda_2\\,\\mathbf{I}  \\end{array}\\right]\\,\\mathbf{a} \\approx\n",
    "  \\left[\\begin{array}{l} - d_{n+1} \\\\\n",
    "      \\lambda_1\\,\\bar{\\mathbf{a}}_1 \\\\ \\lambda_2\\,\\bar{\\mathbf{a}}_2\n",
    "    \\end{array}\\right]\\;,$$\n",
    "\n",
    "where $\\lambda_1$ and $\\lambda_2$ control the filter variability in the two directions. The least-squares solution of this system is\n",
    "\n",
    "$$\\mathbf{a} = \\left(\\mathbf{d}\\,\\mathbf{d}^T + \\lambda^2\\,\\mathbf{I}\\right)^{-1}\\,\n",
    "  \\left(-d_{n+1}\\,\\mathbf{d} + \\lambda_1^2\\,\\bar{\\mathbf{a}}_1 +\n",
    "    \\lambda_1^2\\,\\bar{\\mathbf{a}}_2 \\right)\\;,$$\n",
    "\n",
    "where $\\lambda^2 = \\lambda_1^2+\\lambda_2^2$. The new equation\n",
    "is equivalent to the previous equation with the simple substitution\n",
    "\n",
    "$$\\bar{\\mathbf{a}} = \\displaystyle \\frac{\\lambda_1^2\\,\\bar{\\mathbf{a}}_1 +\n",
    "    \\lambda_2^2\\,\\bar{\\mathbf{a}}_2}{\\lambda_1^2+\\lambda_2^2}\\;.$$\n",
    "\n",
    "Thus, the only change in the algorithm is an increase in the storage to keep track of both $\\bar{\\mathbf{a}}_1$ and $\\bar{\\mathbf{a}}_2$. The extension to more dimensions is analogous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Cost comparison\n",
    "\n",
    "Table 1 compares the computational cost of different approaches to computing prediction-error filters. The cost of streaming PEF is minimal and reduces to the cost of a single convolution. Streaming PEF can capture the input data's non-stationary character without storing multiple copies of the filter.\n",
    "\n",
    "Moreover, all streaming computations are local, which makes them\n",
    "particularly suitable for modern hardware accelerators such as\n",
    "GPGPU (Sanders & Kandrot, 2010) or Intel Xeon Phi (Jeffers & Reinders, 2013).\n",
    "\n",
    "| Method | Storage | Cost |\n",
    "|:-------|:--------|:-----|\n",
    "| Stationary PEF | $O(N_a)$ | $O(N_a^2\\,N_d)$ |\n",
    "| Non-stationary PEF | $O(N_a\\,N_d)$ | $ O(N_a^2\\,N_d)$ |\n",
    "| Streaming PEF | $O(N_a)$ | $O(N_a\\,N_d)$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Missing data interpolation\n",
    "\n",
    "The existence of the exact inversion for the application of a streaming PEF allows for a straightforward approach to missing data interpolation. When reading data in a streaming fashion, every time we meet a missing data point $d_{n+1}$, we can replace its value by a\n",
    "value computed from the residual. The residual value $r_{n+1}$ in this case can be set to zero or to a random number (white noise) with the expected variance of the residual. In the latter case, it is possible to generate multiple equiprobable distributions for the interpolation\n",
    "result (Clapp, 2000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp2 = deepcopy(inp)\n",
    "known = ones(Bool,n1)\n",
    "\n",
    "# Cut holes in the data and create a mask\n",
    "for hole in (55, 153, 246, 301, 376)\n",
    "    inp2[hole:hole+20] .= 0\n",
    "    known[hole:hole+20] .= false\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "function stream_missing!(d::Vector{T}, k::Vector{Bool}, na::Int, ฮป::Real) where T <: Real\n",
    "    a = zeros(T, na) # streaming PEF\n",
    "    da = zero(T) # d (dot) a\n",
    "    dd = zero(T) # d (dot) d\n",
    "    for ia in 1:na\n",
    "        dd += d[ia]*d[ia]\n",
    "    end\n",
    "    for i1 in na+1:n1\n",
    "        if (k[i1]) # from d to r\n",
    "            dn = d[i1]\n",
    "            rn = (dn + da) / (ฮป + dd)\n",
    "        else       # assume r=0\n",
    "            dn = - da\n",
    "            rn = zero(T)\n",
    "            d[i1] = dn\n",
    "        end\n",
    "        # update PEF\n",
    "        for ia in 1:na\n",
    "            a[ia] -= rn * d[i1-ia]\n",
    "        end\n",
    "        # update dd and da\n",
    "        dd += dn*dn - d[i1-na] * d[i1-na]   \n",
    "        da = dn * a[1]\n",
    "        for ia in 2:na\n",
    "            da += a[ia] * d[i1-ia+1]\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ideal = stems(inp,\"ideal \",:blue);\n",
    "plot_hole = stems(inp2,\"input \",:green);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "miss = deepcopy(inp2)\n",
    "stream_missing!(miss,known,2,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_interp = stems(miss,\"filled\",:purple);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(plot_ideal, plot_hole, plot_interp, layout=(3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(\"mstream.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "A simple 1D interpolation example using data from Figure 1 is shown in Figure 2. As evident from the figure, such interpolation, while capable of picking the non-stationary data pattern, remains one-sided and may create discontinuities at the other side of the data gap. We can rerun the streaming PEF using the opposite directions and stack the results to help with this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg; Pkg.add(\"ZipFile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "using ZipFile\n",
    "\n",
    "# download data from a public server\n",
    "download(\"https://zenodo.org/api/records/11099632/files-archive\", \"files.zip\")\n",
    "# unzip the archive file\n",
    "r = ZipFile.Reader(\"files.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary of files for easy access\n",
    "patterns = Dict{String, IO}()\n",
    "for file in r.files\n",
    "    name = splitext(file.name)[1]\n",
    "    patterns[name] = file\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download \"wood\" pattern\n",
    "wood = Array{Float32}(undef, 128, 128) # single-precision array\n",
    "read!(patterns[\"wood\"], wood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(wood,axis=nothing,legend=:none,color=:grays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "function punch_hole(data::Matrix{T}) where T <: Real\n",
    "    # make an elliptical hole\n",
    "    n1, n2 = size(data)\n",
    "    hole = similar(data)\n",
    "    mask = zeros(Bool, n1, n2)\n",
    "    for i2 in 1:n2, i1 in 1:n1\n",
    "        x = (i1-1)/n1 - 0.5\n",
    "        y = (i2-1)/n2 - 0.3\n",
    "        u =  x + y\n",
    "        v = (x - y)/2\n",
    "        if (u*u + v*v < 0.15)\n",
    "            hole[i1,i2] = zero(T)\n",
    "        else\n",
    "            hole[i1,i2] = data[i1,i2]\n",
    "            mask[i1,i2] = true\n",
    "        end\n",
    "    end\n",
    "    return hole, mask\n",
    "end\n",
    "\n",
    "whole, wmask = punch_hole(wood);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "function helix(lag::Vector{Tuple{T, T}}, ci::CartesianIndices) where T <: Integer\n",
    "    \"convert filter lags to helix lags for a given grid\"\n",
    "    # middle of the grid\n",
    "    mid = CartesianIndex(Tuple(last(ci)) .รท 2)\n",
    "    # helix index of middle\n",
    "    hmid = LinearIndices(ci)[mid]\n",
    "    # from Cartesian shift to helix shift\n",
    "    return LinearIndices(ci)[map(x -> CartesianIndex(x) + mid, lag)] .- hmid\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Random\n",
    "\n",
    "function stream_missing_helix!(d, k, \n",
    "                               lag::Vector{Tuple{I, I}},\n",
    "                               ฮป::Real, std=0, seed=1) where I <: Integer\n",
    "    \"Fill missing data in multiple dimensions using streaming PEF on a helix\"\n",
    "    n1, na = length(d), length(lag)\n",
    "    hlag = helix(lag, CartesianIndices(d))\n",
    "    maxlag = maximum(hlag)\n",
    "    T = eltype(d)\n",
    "    a = zeros(T, na) # streaming PEF\n",
    "    da = zero(T) # d (dot) a\n",
    "    dd = zero(T) # d (dot) d\n",
    "    for ia in 1:na\n",
    "        dd += d[maxlag+1-hlag[ia]]^2\n",
    "    end\n",
    "    Random.seed!(seed)\n",
    "    for i1 in maxlag+1:n1\n",
    "        if (k[i1])\n",
    "            dn = d[i1]\n",
    "            rn = (dn + da) / (ฮป + dd)\n",
    "        else # assume r_n is random\n",
    "            rn = std * randn() / ฮป\n",
    "            dn = rn * (ฮป + dd) - da\n",
    "            d[i1] = dn\n",
    "        end\n",
    "        # update PEF\n",
    "        for ia in 1:na\n",
    "            a[ia] -= rn * d[i1-hlag[ia]]\n",
    "        end\n",
    "        # update dd and da\n",
    "        dd += dn * dn - d[i1-maxlag] * d[i1-maxlag]   \n",
    "        da = dn * a[1]\n",
    "        for ia in 2:na\n",
    "            da += a[ia] * d[i1+1-hlag[ia]]\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11 x 11 PEF\n",
    "lag=[(x,0) for x in 1:5]\n",
    "for k in 1:10\n",
    "    lag = vcat(lag,[(x,k) for x in -5:5])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "function fill_hole(forward::Bool, hole, mask, pad::Integer, noise=0, seed=1)\n",
    "    if forward\n",
    "        holepad = hcat(zeros(Float32, size(hole, 1), pad), hole)\n",
    "        maskpad = hcat(zeros(Bool, size(hole, 1), pad), mask)\n",
    "        stream_missing_helix!(holepad, maskpad, lag, 1e6, noise, seed)\n",
    "        return holepad[:,pad+1:end]\n",
    "    else\n",
    "        rhole = reverse(hole)\n",
    "        rmask = reverse(mask)\n",
    "        holepad = hcat(zeros(Float32, size(rhole, 1), pad), rhole)\n",
    "        maskpad = hcat(zeros(Bool, size(rhole, 1), pad), rmask)\n",
    "        stream_missing_helix!(holepad, maskpad, lag, 1e6, noise, seed+1)\n",
    "        return reverse(holepad[:,pad+1:end])\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled1 = fill_hole(true, whole, wmask, 20);\n",
    "filled2 = fill_hole(false, whole, wmask, 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot2(data, title) = heatmap(data, axis=nothing, yflip=:true, clim=(-137, 137),\n",
    "                             legend=:none, color=:grays, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = plot2(filled1, \"(a) Filled 1\")\n",
    "p2 = plot2(filled2, \"(a) Filled 2\")\n",
    "p3 = plot2(filled1 + filled2 - whole, \"(c) Filled 1+2\")\n",
    "plot(p1, p2, p3, layout=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(\"interp.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled = fill_hole(true,  whole, wmask, 20, 2) + \n",
    "         fill_hole(false, whole, wmask, 20, 2) - whole\n",
    "\n",
    "p1 = plot2(wood, \"(a) Ideal\") \n",
    "p2 = plot2(whole, \"(b) Gapped\")\n",
    "p3 = plot2(filled, \"(c) Filled\")\n",
    "plot(p1, p2, p3, layout=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(\"wood-hole.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "Figure 3 shows a 2D missing data interpolation test using a synthetic pattern from  Claerbout & Brown (1999). The input data for this test is shown in Figure 4b. Interpolation proceeds by running the streaming PEF twice in the forward and backward directions (Figures 3a and 3b) and averaging the interpolation results (Figure 3c.) The cost of such procedure is the cost of two convolutions, as opposed to multiple iterations required in the conventional approach to missing data interpolation with PEFs  (Naghizadeh & Sacchi, 2010; Liu & Fomel, 2011; Claerbout, 2014). A better interpolation result in Figure 4c is achieved by filling the residual inside the gap with small-variance white noise instead of zeros while reconstructing\n",
    "the data from the residual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Array{Plots.Plot}(undef,3)\n",
    "for k in 1:3\n",
    "    filled = fill_hole(true,  whole, wmask, 20, 2, k) + \n",
    "             fill_hole(false, whole, wmask, 20, 2, k+3) - whole\n",
    "    p[k] = plot2(filled, \"Realization $k\") \n",
    "end\n",
    "plot(p[1], p[2], p[3], layout=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(\"realiz.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "The random residual approach can generate multiple equiprobable realizations for the missing data interpolation problem in the spirit of geostatistical stochastic simulations (Clapp, 2000). Figure 5 shows three realizations created using different seeds for the pseudorandom number generator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"herring\" pattern\n",
    "herr = Array{Float32}(undef, 128, 128) # single-precision array\n",
    "# read data\n",
    "read!(patterns[\"herr\"], herr)\n",
    "# make a hole\n",
    "hhole, hmask = punch_hole(herr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled = fill_hole(true,  hhole, hmask, 20, 6) + \n",
    "         fill_hole(false, hhole, hmask, 20, 6) - hhole\n",
    "\n",
    "p1 = plot2(herr, \"(a) Ideal\") \n",
    "p2 = plot2(hhole, \"(b) Gapped\")\n",
    "p3 = plot2(filled, \"(c) Filled\")\n",
    "plot(p1, p2, p3, layout=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(\"herr-hole.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "Figure 6 shows a similar interpolation test applied to 2D data with a non-stationary pattern. Although streaming PEF fails to achieve a perfect reconstruction in this case, it manages to capture most of the pattern and hide the location of the gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"seismic\" pattern\n",
    "seis = Array{Float32}(undef, 250, 125) # single-precision array\n",
    "# read data\n",
    "read!(patterns[\"seis\"], seis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics\n",
    "\n",
    "# normalize\n",
    "m = mean(seis)\n",
    "seis .-= m\n",
    "scale = std(wood)/std(seis)\n",
    "seis *= scale\n",
    "\n",
    "# make a hole\n",
    "shole, smask = punch_hole(seis);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled = fill_hole(true,  shole, smask, 20, 0.7) + \n",
    "         fill_hole(false, shole, smask, 20, 0.7) - shole\n",
    "\n",
    "p1 = plot2(seis, \"(a) Ideal\") \n",
    "p2 = plot2(shole, \"(b) Gapped\")\n",
    "p3 = plot2(filled, \"(c) Filled\")\n",
    "plot(p1, p2, p3, layout=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig(\"WGstack-hole.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "Figure 7 shows a similar test applied to 2D seismic data. The pattern made by reflection events with variable slopes is well captured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "function stream_helix!(inv::Bool, d, r, lag::Vector{Tuple{I, I}}, ฮป::Real) where I <: Integer\n",
    "    n1, na = length(d), length(lag)\n",
    "    hlag = helix(lag, CartesianIndices(d))\n",
    "    maxlag = maximum(hlag)\n",
    "    T = eltype(d)\n",
    "    a = zeros(T, na) # streaming PEF\n",
    "    for i1 in 1:maxlag\n",
    "        if (inv) \n",
    "            d[i1] = r[i1]\n",
    "        else \n",
    "            r[i1] = d[i1]\n",
    "        end\n",
    "    end\n",
    "    da = zero(T) # d (dot) a\n",
    "    dd = zero(T) # d (dot) d\n",
    "    for ia in 1:na      \n",
    "        dd += d[maxlag+1-hlag[ia]]^2\n",
    "    end\n",
    "    for i1 in maxlag+1:n1\n",
    "        if (inv) \n",
    "            rn = r[i1] / ฮป \n",
    "            dn = rn * (ฮป + dd) - da\n",
    "            d[i1] = dn\n",
    "        else \n",
    "            dn = d[i1]\n",
    "            rn = (dn + da) / (ฮป + dd)\n",
    "            r[i1] = ฮป * rn\n",
    "        end\n",
    "        # update PEF\n",
    "        for ia in 1:na\n",
    "            a[ia] -= rn * d[i1-hlag[ia]]\n",
    "        end\n",
    "        # update dd and da\n",
    "        dd += dn * dn - d[i1-maxlag] * d[i1-maxlag]    \n",
    "        da = dn * a[1]\n",
    "        for ia in 2:na\n",
    "            da += a[ia] * d[i1+1-hlag[ia]]\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply helix filter\n",
    "pad = hcat(zeros(Float32, size(seis, 1), 20), seis)\n",
    "res= similar(pad)\n",
    "stream_helix!(false, pad, res, lag, 1e6) # pad -> res\n",
    "stream_helix!(true,  pad, res, lag, 1e6) # pad <- res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = plot2(seis, \"(a) Input\") \n",
    "p2 = plot2(20*res[:,21:end], \"(b) Residual (x 20)\")\n",
    "p3 = plot2(pad[:,21:end], \"(c) Inverse\")\n",
    "plot(p1, p2, p3, layout=(1, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "In this case, removing dominant reflection events by PEF filtering leaves behind weaker hyperbolic diffraction events (Figure 8). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "A streaming application, where the adaptive filter is updated one data point at a time, is appropriate in a continuous stream of large amounts of data, such as in passive monitoring of carbon storage (Alumbaugh et al., 2024). In more typical scenarios, where the data are immediately accessible, more accurate results can be achieved with other forms of regularization, such as regularizing adaptive filter coefficients with smoothing shaping operators (Fomel, 2009; Liu \\& Fomel, 2011; Liu et al., 2012). For greater efficiency, a hybrid regularization strategy can be developed. Such strategies are discussed by Geng et al. (2024), who also extend the streaming approach to other applications of seismic attributes.\n",
    "\n",
    "In applications such as missing data reconstruction, the streaming approach represents an extreme point of the accuracy-efficiency trade-off. To achieve better accuracy, some of the efficiency can be sacrificed at the expense of performing extra iterations. The presented approach is also limited to situations of missing values in regularly sampled data and will need to be modified for situations of irregular data.\n",
    "\n",
    "In multidimensional applications, the helical boundary conditions allow for easy invertibility (Claerbout, 1998) but are not always appropriate. In this case, extra accuracy can also be bought at the cost of sacrificing some of the efficiency.\n",
    "\n",
    "We hope that providing reproducible benchmarks with this paper will invite other researchers to make direct comparisons with more advanced methods. Such comparisons are beyond the scope of this paper because they would require a different codebase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "We have presented an efficient approach to computing and applying non-stationary prediction-error filters (PEFs). Instead of storing multiple copies of varying filters, the streaming approach stores only one copy and updates the filter on the fly with every new data point. The cost of this procedure is equivalent to the cost of a single convolution and does not require multiple iterations. Moreover, the non-linear operation of estimating and applying a streaming PEF has an exact inverse, which becomes helpful in missing data interpolation\n",
    "problems. A streaming approach to missing data interpolation does not require iterations and can be accomplished effectively at the cost of two convolutions. We anticipate many possible applications of the proposed technique in geophysical estimation problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Alumbaugh, D.L., Correa, J., Jordan, P., Petras, B., Chundur, S. and Abriel, W., 2024. An assessment of the role of geophysics in future US geologic carbon storage projects. The Leading Edge, 43, 72-83.\n",
    "\n",
    "Bezanson, J., A. Edelman, S. Karpinski, and V. B. Shah, 2017, Julia: A fresh approach to numerical computing: SIAM Review, 59, 65-98.\n",
    "\n",
    "Claerbout, J., 1998, Multidimensional recursive filters via a helix: Geophysics, 63, 1532โ1541.\n",
    "\n",
    "Claerbout, J., and M. Brown, 1999, Two-dimensional textures and prediction-error filters: 61st Mtg., Eur. Assn. Geosci. Eng., Session:1009.\n",
    "\n",
    "Claerbout, J. F., 2014, Geophysical image estimation by example: Environmental soundings image enhancement: Lulu. (http://sep.stanford.edu/sep/prof/).\n",
    "\n",
    "Clapp, R., 2000, Multiple realizations using standard inversion techniques, in SEP-105: Stanford Exploration Project, 67โ78.\n",
    "\n",
    "Crawley, S., J. Claerbout, and R. Clapp, 1999, Interpolation with smoothly non-stationary prediction-error filters: 69th Annual International Meeting, SEG, Expanded Abstracts, 1154โ1157.\n",
    "\n",
    "Curry, W., 2003, Interpolation of irregularly sampled data with nonstationary, multi- scale prediction-error filters: 73th Annual International Meeting, SEG, Expanded Abstracts, 1913โ1916.\n",
    "\n",
    "Fomel, S., 2009, Adaptive multiple subtraction using regularized nonstationary regression: Geophysics, 74, V25โV33.\n",
    "\n",
    "Geng, Z., Fomel, S., Liu, Y., Wang, Q., Zheng, Z. and Chen, Y., 2024. Streaming seismic attributes. Geophysics, 89, A7-A10.\n",
    "\n",
    "Granger, B.E. and F. P\\'{e}rez, F., 2021, Jupyter: Thinking and storytelling with code and data: Computing in Science \\& Engineering, 23, 7-14.\n",
    "\n",
    "Hager, W. W., 1989, Updating the inverse of a matrix: SIAM Review, 31, 221โ239. Jeffers, J., and J. Reinders, 2013, Intel Xeon Phi coprocessor high-performance programming: Morgan Kaufmann.\n",
    "\n",
    "Haykin, S., 2002. Adaptive Filter Theory. Prentice-Hall.\n",
    "\n",
    "Liu, G., X. C. J. Du, and K. Wu, 2012, Random noise attenuation using f-x regularized nonstationary autoregression: Geophysics, 77, V61โV69.\n",
    "\n",
    "Liu, Y., and S. Fomel, 2011, Seismic data interpolation beyond aliasing using regularized nonstationary autoregression: Geophysics, 76, V69โV77.\n",
    "\n",
    "Naghizadeh, M., and M. D. Sacchi, 2010, Robust reconstruction of aliased data using autoregressive spectral estimates: Geophysical Prospecting, 58, 1049โ1062.\n",
    "\n",
    "Robinson, E. A., and O. M. Osman, eds., 1996, Deconvolution 2: Soc. of Expl. Geophys.\n",
    "\n",
    "Ruan, K., J. Jennings, E. Biondi, R. G. Clapp, S. A. Levin, and J. Claerbout, 2015, Industrial scale high-performance adaptive filtering with PEF applications, in SEP-160: Stanford Exploration Project, 177โ188.\n",
    "\n",
    "Sanders, J., and E. Kandrot, 2010, CUDA by example: An introduction to General- Purpose GPU programming: Addison-Wesley Professional.\n",
    "\n",
    "Webster, G. M., ed., 1978, Deconvolution: Soc. of Expl. Geophys.\n",
    "\n",
    "Widrow, B., and S.D. Stearns, Adaptive Signal Processing: Prentice Hall, 1985."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
